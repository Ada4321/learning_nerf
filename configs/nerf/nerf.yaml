task: nerf
gpus: [0]
exp_name: 'nerf'
scene: 'lego'

# module path
train_dataset_module: lib.datasets.nerf.synthetic
val_dataset_module: lib.datasets.nerf.synthetic 
test_dataset_module: lib.datasets.nerf.synthetic
network_module: lib.networks.nerf.network
loss_module: lib.train.losses.nerf
evaluator_module: lib.evaluators.nerf
visualizer_module: lib.visualizers.nerf

task_arg:
    N_rays: 1024 # number of rays per training iteration
    chunk_size: 4096         # chunkify points
    chunk_size_ray: 1024*32  # chunkify rays
    white_bkgd: True # use white background
    cascade_samples: [64, 128] # importance sampling, you can set it to [64] for the initial implemetation
    stratified: True
    scene_bounds:
        near: 0.
        far: 0.

network:
    nerf:
        W: 256 # width
        D: 8 # depth
        V_D: 1 # appearance depth
    xyz_encoder:
        type: 'frequency' # positional encoding
        input_dim: 3
        freq: 10
        skips: [4]
        act: ['relu','relu','relu','relu','relu','relu','relu','relu','']
    dir_encoder:
        type: 'frequency'
        input_dim: 3
        freq: 4
        skips: []
        act: ['relu','sigmoid']

train_dataset:
    data_root: 'data/nerf_synthetic'
    split: 'train'
    input_ratio: 1. # input image ratio, you can set it to 0.5 to acclerate training
    cams: [0, -1, 1] # input cameras, you can use this variable to select training images
    batching_stratrgy: 'cross'

test_dataset:
    data_root: 'data/nerf_synthetic'
    split: 'val'
    input_ratio: 0.5
    cams:: [0, -1, 1]

test_dataset:
    data_root: 'data/nerf_synthetic'
    split: 'test'
    input_ratio: 0.5
    cams: [0, -1, 10]

train:
    batch_size: 1
    lr: 5e-4
    weight_decay: 0.
    epoch: 400
    scheduler:
        type: 'exponential'
        gamma: 0.1
        decay_epochs: 1000
    num_workers: 4

test:
    batch_size: 1

ep_iter: 500
save_ep: 20
eval_ep: 20       # 10000 iterations
save_latest_ep: 5 # 2500 iterations
log_interval: 10
result_dir: ''
vis_dir: ''